###K-FOLD CROSS VALIDATION
# define training control
World_train_control <- trainControl(method="cv", number=10)
# fix the parameters of the algorithm
World_grid <- expand.grid(.fL=c(0), .usekernel=c(FALSE), .adjust=c(0))
# train the model
World_model <- train(as.factor(Ranking_Bin)~., data=Bin_World, trControl=World_train_control, method="nb", tuneGrid=World_grid)
# summarize results
print(World_model)
###BOOTSTRAP
# define training control
World_train_control <- trainControl(method="boot", number=100)
# train the model
World_model <- train(as.factor(Ranking_Bin)~., data=Bin_World, trControl=World_train_control, method="nb")
# summarize results
print(World_model)
library("e1071", lib.loc="~/R/win-library/3.3")
###BOOTSTRAP
# define training control
World_train_control <- trainControl(method="boot", number=100)
# train the model
World_model <- train(as.factor(Ranking_Bin)~., data=Bin_World, trControl=World_train_control, method="nb")
# summarize results
print(World_model)
library("klaR", lib.loc="~/R/win-library/3.3")
###BOOTSTRAP
# define training control
World_train_control <- trainControl(method="boot", number=100)
# train the model
World_model <- train(as.factor(Ranking_Bin)~., data=Bin_World, trControl=World_train_control, method="nb")
# summarize results
print(World_model)
library("caret", lib.loc="~/R/win-library/3.3")
##DATA SPLIT
# define an 80%/20% train/test split of the dataset
split=0.80
World_trainIndex <- createDataPartition(Bin_World$Ranking_Bin, p=split, list=FALSE)
World_data_train <- Bin_World[World_trainIndex,]
World_data_test <- Bin_World[-World_trainIndex,]
# train a naive bayes model
World_model <- naiveBayes(as.factor(Ranking_Bin)~., data=World_data_train)
# make predictions
World_x_test <- World_data_test[,1:10]
World_y_test <- World_data_test[,11]
World_predictions <- predict(World_model, World_x_test)
Bin_World <- read.csv("C:/Users/kjmac/Desktop/Ryerson/136 CAPSTONE/GitHub/Working Files/Bins/Bin_2015_WorldUniversity_Working.csv")
View(Bin_World)
###DATA SPLIT
# define an 80%/20% train/test split of the dataset
split=0.80
World_trainIndex <- createDataPartition(Bin_World$Ranking_Bin, p=split, list=FALSE)
World_data_train <- Bin_World[World_trainIndex,]
World_data_test <- Bin_World[-World_trainIndex,]
# train a naive bayes model
World_model <- naiveBayes(as.factor(Ranking_Bin)~., data=World_data_train)
# make predictions
World_x_test <- World_data_test[,1:10]
World_y_test <- World_data_test[,11]
World_predictions <- predict(World_model, World_x_test)
confusionMatrix(World_predictions, World_y_test)
###BOOTSTRAP
# define training control
World_train_control <- trainControl(method="boot", number=100)
# train the model
World_model <- train(as.factor(Ranking_Bin)~., data=Bin_World, trControl=World_train_control, method="nb")
# summarize results
print(World_model)
###K-FOLD CROSS VALIDATION
# define training control
World_train_control <- trainControl(method="cv", number=10)
# fix the parameters of the algorithm
World_grid <- expand.grid(.fL=c(0), .usekernel=c(FALSE), .adjust=c(0))
# train the model
World_model <- train(as.factor(Ranking_Bin)~., data=Bin_World, trControl=World_train_control, method="nb", tuneGrid=World_grid)
# summarize results
print(World_model)
World_x<-subset(Bin_World,select=-Ranking_Bin)
World_y<-Ranking_Bin
svm_model_World<-svm(World_x,World_y,type="C-classification")
summary(svm_model_World)
World_predict<-predict(svm_model_World,World_x)
system.time(World_predict<-predict(svm_model_World,World_x))
table(World_predict,World_y)
World_svm_tune<-tune(svm, train.x = World_x, train.y = World_y, kernel="radial", ranges=list(cost=10^(-1:2),gamma=c(.5,1,2)))
print(World_svm_tune)
svm_model_World_after_tune<-svm(Ranking_Bin ~ ., data=Bin_World, type="C-classification", kernel="radial",cost=1,gamma=0.5)
summary(svm_model_World_after_tune)
World_predict_after_tune<-predict(svm_model_World_after_tune,Times_x)
system.time(predict(svm_model_World_after_tune,World_x))
table(World_predict_after_tune,World_y)
Bin_World <- read.csv("C:/Users/kjmac/Desktop/Ryerson/136 CAPSTONE/GitHub/Working Files/Bins/Bin_2015_WorldUniversity_Working.csv")
View(Bin_World)
attach(Bin_World)
World_x<-subset(Bin_World,select=-Ranking_Bin)
World_y<-Ranking_Bin
svm_model_World<-svm(World_x,World_y,type="C-classification")
summary(svm_model_World)
World_predict<-predict(svm_model_World,World_x)
system.time(World_predict<-predict(svm_model_World,World_x))
table(World_predict,World_y)
World_svm_tune<-tune(svm, train.x = World_x, train.y = World_y, kernel="radial", ranges=list(cost=10^(-1:2),gamma=c(.5,1,2)))
print(World_svm_tune)
svm_model_World_after_tune<-svm(Ranking_Bin ~ ., data=Bin_World, type="C-classification", kernel="radial",cost=1,gamma=0.5)
summary(svm_model_World_after_tune)
World_predict_after_tune<-predict(svm_model_World_after_tune,Times_x)
system.time(predict(svm_model_World_after_tune,World_x))
table(World_predict_after_tune,World_y)
World_x<-subset(Bin_World,select=-Ranking_Bin)
World_y<-Ranking_Bin
svm_model_World<-svm(World_x,World_y,type="C-classification")
summary(svm_model_World)
World_predict<-predict(svm_model_World,World_x)
system.time(World_predict<-predict(svm_model_World,World_x))
table(World_predict,World_y)
World_svm_tune<-tune(svm, train.x = World_x, train.y = World_y, kernel="radial", ranges=list(cost=10^(-1:2),gamma=c(.5,1,2)))
print(World_svm_tune)
svm_model_World_after_tune<-svm(Ranking_Bin ~ ., data=Bin_World, type="C-classification", kernel="radial",cost=1,gamma=0.5)
summary(svm_model_World_after_tune)
World_predict_after_tune<-predict(svm_model_World_after_tune,World_x)
system.time(predict(svm_model_World_after_tune,World_x))
table(World_predict_after_tune,World_y)
# make predictions
World_x_test <- World_data_test[,1:10]
World_y_test <- World_data_test[,11]
World_predictions <- predict(World_model, World_x_test)
#Confusion Matrix
confusionMatrix(World_data_train$Ranking_Bin,predict(svm_model_world_after_tune,World_data_train))
confusionMatrix(World_data_train$Ranking_Bin,predict(svm_model_World_after_tune,World_data_train))
###DATA SPLIT
# define an 80%/20% train/test split of the dataset
split=0.80
World_trainIndex <- createDataPartition(Bin_World$Ranking_Bin, p=split, list=FALSE)
World_data_train <- Bin_World[World_trainIndex,]
World_data_test <- Bin_World[-World_trainIndex,]
# train a naive bayes model
World_model <- naiveBayes(as.factor(Ranking_Bin)~., data=World_data_train)
# make predictions
World_x_test <- World_data_test[,1:10]
World_y_test <- World_data_test[,11]
World_predictions <- predict(World_model, World_x_test)
#Confusion Matrix
confusionMatrix(World_data_train$Ranking_Bin,predict(svm_model_World_after_tune,World_data_train))
###BOOTSTRAP
# define training control
World_train_control <- trainControl(method="boot", number=100)
# train the model
World_model <- train(as.factor(Ranking_Bin)~., data=Bin_World, trControl=World_train_control, method="nb")
# summarize results
print(World_model)
###K-FOLD CROSS VALIDATION
# define training control
World_train_control <- trainControl(method="cv", number=10)
# fix the parameters of the algorithm
World_grid <- expand.grid(.fL=c(0), .usekernel=c(FALSE), .adjust=c(0))
# train the model
World_model <- train(as.factor(Ranking_Bin)~., data=Bin_World, trControl=World_train_control, method="nb", tuneGrid=World_grid)
# summarize results
print(World_model)
###REPEATED K-FOLD CROSS VALIDATION
# define training control
World_train_control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
World_model <- train(as.factor(Ranking_Bin)~., data=Bin_World, trControl=World_train_control, method="nb")
# summarize results
print(World_model)
###LEAVE OUT ONE CROSS VALIDATION
# define training control
World_train_control <- trainControl(method="LOOCV")
# train the model
World_model <- train(as.factor(Ranking_Bin)~., data=Bin_World, trControl=World_train_control, method="nb")
# summarize results
print(World_model)
